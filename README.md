# JEMMA
JAX-based LLM inference

# TODO
gemma 2B
- [x] Layernorm
- [ ] Dropout
- [ ] Causal multi-head attention
     - [ ] Multi-query attention 
- [x] Positional embedding
- [x] Tokenizer
- [ ] KV Cache

Later
- [ ] FlashAttention (CUDA and Triton kernels)
- [ ] Weight Quantization
- [ ] OpenAI-compatible API